---
layout: page
title: About
permalink: /about/
---

```
  _____ _                 _        _     _       
 |_   _(_)_ __   __ _  __| | ___  | |   (_)_   _ 
   | | | | '_ \ / _` |/ _` |/ _ \ | |   | | | | |
   | | | | | | | (_| | (_| |  __/ | |___| | |_| |
   |_| |_|_| |_|\__, |\__,_|\___| |_____|_|\__,_|
                |___/                             
```

# ğŸ‘‹ Hi, I'm Tingde Liu

> **Embodied AI Engineer | Vision-Language Navigation Specialist**

Welcome to my personal blog! I'm an **Embodied AI engineer** specializing in **Vision-Language Navigation (VLN)** at **Leibniz UniversitÃ¤t Hannover (LUH)** in Germany.

## ğŸ“ Education

**Leibniz UniversitÃ¤t Hannover (LUH)**  
M.Sc. in Robotics and Autonomous Systems  
ğŸ“ Hannover, Germany ğŸ‡©ğŸ‡ª

## ğŸ”¬ Research Interests

My research focuses on **Embodied AI** - building intelligent agents that can perceive, reason, and act in physical and virtual environments through natural language understanding:

### Primary Focus:
- **ğŸ—£ï¸ Vision-Language Navigation (VLN)** - Enabling robots to navigate using natural language instructions
- **ğŸ¤– Embodied AI** - Developing agents that understand and interact with 3D environments
- **ğŸ¯ Vision-Language-Action (VLA)** - Multimodal models for robotic control and manipulation

### Core Technical Areas:
- **ğŸ“ SLAM & Spatial Mapping** - Building spatial understanding for autonomous navigation
- **ğŸ§  Large Language Models for Robotics** - Leveraging LLMs for spatial reasoning and task planning
- **ğŸ¨ 3D Scene Understanding** - Point cloud processing, depth estimation, and semantic segmentation
- **ğŸ‘ï¸ Multi-Modal Learning** - Fusing vision, language, and action for embodied intelligence
- **ğŸ›¤ï¸ Path Planning & Navigation** - Intelligent navigation in complex, dynamic environments
- **ğŸ”Œ Multi-Sensor Fusion** - Integrating cameras, LiDAR, and other sensors for robust perception

## ğŸ’» Technical Skills

```yaml
Programming:
  - Primary: Python, C++
  - Research: MATLAB
  - Tools: Bash, Git

Deep_Learning:
  - Frameworks: PyTorch, TensorFlow, Hugging Face Transformers
  - Models: Vision Transformers, CLIP, BERT, GPT, LLaMA
  - Training: Multi-GPU training, Mixed precision, Model fine-tuning

Computer_Vision:
  - Libraries: OpenCV, PIL, Albumentations
  - 3D Vision: Point Cloud Library (PCL), Open3D
  - Tasks: Object detection, Semantic segmentation, Depth estimation

Robotics:
  - ROS/ROS2: Navigation stack, sensor integration
  - Simulation: Habitat, AI2-THOR, Matterport3D
  - SLAM: ORB-SLAM, LiDAR mapping

NLP_and_Multimodal:
  - Vision-Language models (CLIP, BLIP, Flamingo)
  - Language grounding in 3D scenes
  - Instruction following and reasoning
  - Retrieval-Augmented Generation (RAG)

Development_Tools:
  - Version Control: Git, GitHub
  - Containers: Docker, Singularity
  - HPC: SLURM, multi-node training
  - IDEs: VS Code, PyCharm, Jupyter
```

## ğŸš€ Notable Projects & Research

```python
projects = {
    "VLN_Research": {
        "description": "Vision-Language Navigation algorithms and implementations",
        "tech": ["PyTorch", "Transformers", "Habitat-Sim"],
        "focus": ["Instruction following", "Spatial reasoning", "Cross-modal learning"]
    },
    "MMS_LLM": {
        "description": "3D Large Language Model for spatial understanding",
        "institution": "Institute of Cartography and Geoinformatics, LUH",
        "tech": ["LLMs", "3D Vision", "Multi-modal fusion"]
    },
    "SLAM_PathPlanning": {
        "description": "Simultaneous Localization, Mapping and Path Planning",
        "tech": ["ROS", "C++", "Optimization algorithms"],
        "application": "Autonomous navigation systems"
    },
    "RAG_pdf": {
        "description": "Retrieval-Augmented Generation for document understanding",
        "tech": ["LangChain", "Vector DB", "Embeddings"],
        "use_case": "Intelligent document analysis"
    },
    "Laserscanning_3D": {
        "description": "3D Point Cloud Processing and Interpretation",
        "tech": ["PCL", "Open3D", "LiDAR"],
        "tasks": ["Registration", "Segmentation", "Modeling"]
    }
}
```

### Key Research Projects:
- **ğŸ—ºï¸ Vision-Language Navigation (VLN)** - Developing algorithms for language-guided robot navigation
- **ğŸ§  MMS-LLM** - 3D large language model research at Institute of Cartography and Geoinformatics
- **ğŸ¤– Embodied AI Agents** - Building agents that understand and navigate 3D environments
- **ğŸ“ SLAM & Path Planning** - Real-time localization and intelligent path planning
- **â˜ï¸ Point Cloud Processing** - Laserscanning modeling and 3D scene interpretation
- **ğŸ” RAG Systems** - Retrieval-augmented generation for knowledge-intensive tasks

You can explore more on my [GitHub](https://github.com/TingdeLiu).

## ğŸŒ Connect With Me

<div align="center">

[![GitHub](https://img.shields.io/badge/GitHub-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/TingdeLiu)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/tingde-liu-379818270/)
[![Email](https://img.shields.io/badge/Email-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:tingde.liu.ai@gmail.com)

</div>

```bash
$ whoami
tingde-liu

$ cat /etc/os-release | grep PRETTY_NAME
PRETTY_NAME="Embodied AI Engineer"

$ echo $RESEARCH_INTERESTS
Vision-Language-Navigation:Embodied-AI:VLA:SLAM

$ curl -s https://api.github.com/users/TingdeLiu | jq '.bio'
"Bridging Language and Action in Embodied Intelligence"
```

## ğŸ“ About This Blog

This blog is my digital lab notebook where I document my journey in **Embodied AI** and **Vision-Language Navigation**. Here you'll find:

- ğŸ—ºï¸ **VLN Research** - Latest developments in vision-language navigation
- ğŸ¤– **Embodied AI** - Insights on building intelligent embodied agents
- ğŸ“š **Paper Reviews** - Deep dives into cutting-edge research papers
- ğŸ’¡ **Implementation Notes** - Practical guides and technical insights
- ğŸ”¬ **Experiments** - Research experiments and ablation studies
- ğŸ› ï¸ **Tools & Frameworks** - Reviews of useful libraries and platforms

All blog posts are archived in the `_posts` folder. If you find this blog useful, feel free to star it on [GitHub](https://github.com/TingdeLiu/tingdeliu.github.io)! â­

## ğŸ“„ Copyright Notice

All content on this blog represents my original research notes and technical writing. Please contact me for authorization before reusing or reposting any articles.

---

<div align="center">

**æŒç»­æ¢ç´¢å…·èº«æ™ºèƒ½çš„å‰æ²¿ | Continuously Exploring the Frontiers of Embodied AI**

```
if (robot.understand(language) && robot.perceive(environment)) {
    robot.navigate(goal);
    success = true;
}
```

ğŸ’¬ *"Teaching machines to see, understand, and navigate the world through language"*

</div>
